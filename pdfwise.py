# -*- coding: utf-8 -*-
"""pdfwise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vjiCKaYpuDxP5Ua5vuQoJdp8kQSrl_sA
"""

!pip install langchain-google-genai

!pip install -U langchain-community
!pip install langchain
!pip install faiss-cpu
!pip install langchain_google_genai
!pip install wikipedia

!pip install pypdf

pip install gradio langchain faiss-cpu PyPDF2 google-generativeai langchain-community

!pip install -q langchain langchain-google-genai gradio faiss-cpu nest_asyncio

import os
import gradio as gr
import nest_asyncio

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

nest_asyncio.apply()

GOOGLE_API_KEY = "AIzaSyA4DOChhpGmaH_pfly9stFkXfrAY-Z1wZc"

qa_chain = None

async def process_pdf(file):
    global qa_chain
    try:
        loader = PyPDFLoader(file.name)
        documents = loader.load()

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = splitter.split_documents(documents)

        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=GOOGLE_API_KEY
        )

        db = FAISS.from_documents(chunks, embeddings)
        retriever = db.as_retriever()

        llm = ChatGoogleGenerativeAI(
            model="models/gemini-2.5-pro",
            google_api_key=GOOGLE_API_KEY
        )

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=False
        )
        return "‚úÖ PDF processed successfully!"
    except Exception as e:
        return f"‚ùå PDF Error: {str(e)}"

async def ask_question(question):
    global qa_chain
    if not qa_chain:
        return "‚ö†Ô∏è Please upload a PDF first."
    try:
        result = await qa_chain.acall({"query": question})
        return result["result"]
    except Exception as e:
        return f"‚ùå Question Error: {str(e)}"

# Use Gradio's supported theme with hues
theme = gr.themes.Soft(
    primary_hue="indigo",
    secondary_hue="cyan",
    neutral_hue="slate"
)

with gr.Blocks(theme=theme, css="""
    .gr-button {
        background: linear-gradient(to right, #4F46E5, #06B6D4) !important;
        color: white !important;
        border-radius: 8px !important;
        font-size: 16px !important;
    }
    .gr-textbox textarea {
        font-size: 16px !important;
    }
""") as demo:
    gr.Markdown("""
    <h1 style='text-align: center; color: #4F46E5;'>üìÑ PDF Question Answering Bot</h1>
    <p style='text-align: center; font-size: 18px; color: #334155;'>
        Upload a PDF and ask questions. Powered by <strong>Gemini</strong> + <strong>LangChain</strong>
    </p>
    """)

    with gr.Row():
        pdf_input = gr.File(label="üì§ Upload your PDF", file_types=[".pdf"])
        status_output = gr.Textbox(label="üìå PDF Status", interactive=False)

    gr.Markdown("---")

    with gr.Row():
        question_input = gr.Textbox(
            label="‚ùì Ask a Question",
            placeholder="Type your question here...",
            lines=1
        )
        ask_btn = gr.Button("üí¨ Get Answer")

    answer_output = gr.Textbox(
        label="üìò Answer",
        lines=6,
        interactive=False
    )

    pdf_input.change(fn=process_pdf, inputs=pdf_input, outputs=status_output)
    ask_btn.click(fn=ask_question, inputs=question_input, outputs=answer_output)
    question_input.submit(fn=ask_question, inputs=question_input, outputs=answer_output)

demo.launch()